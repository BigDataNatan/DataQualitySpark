{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef55f048",
   "metadata": {},
   "source": [
    "## Gerador de DataSet em CSV para o Exercício\n",
    "Execute o Script abaixo para gerar o Dataset para ser utilizado no [exercicio](../exercicio.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c2dcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de Logística Bruto gerado em: data/logistica_raw.csv\n",
      "\n",
      "--- INGESTÃO BEM-SUCEDIDA (5 linhas brutas) ---\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "|ID_RASTREIO|DATA_ENVIO_RAW|CUSTO_FRETE_RAW|CIDADE_DESTINO|STATUS_ENTREGA|\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "|      L9001|    2024-05-10|          15.50|     Sao Paulo|      ENTREGUE|\n",
      "|      L9002|    2024/05/11|             22|            00|           Rio|\n",
      "|      L9003|    2024-05-12|         100.00|      Salvador|          NULL|\n",
      "|      L9004|    2024-05-12|           NULL|            BH|      PENDENTE|\n",
      "|      L9004|    2024-05-12|           NULL|            BH|      PENDENTE|\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "\n",
      "root\n",
      " |-- ID_RASTREIO: string (nullable = true)\n",
      " |-- DATA_ENVIO_RAW: string (nullable = true)\n",
      " |-- CUSTO_FRETE_RAW: string (nullable = true)\n",
      " |-- CIDADE_DESTINO: string (nullable = true)\n",
      " |-- STATUS_ENTREGA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import os\n",
    "\n",
    "# 1. Inicialização da SparkSession (garantir que está rodando)\n",
    "spark = SparkSession.builder.appName(\"DesafioLogistica\").getOrCreate()\n",
    "\n",
    "# --- DADOS BRUTOS (Substitui o createDataFrame) ---\n",
    "\n",
    "# CORREÇÃO: Usamos o caminho ABSOLUTO do contêiner para o volume 'data'\n",
    "caminho_local_data = \"data/\"\n",
    "nome_arquivo = \"logistica_raw.csv\"\n",
    "caminho_completo = os.path.join(caminho_local_data, nome_arquivo)\n",
    "\n",
    "csv_content = \"\"\"ID_RASTREIO,DATA_ENVIO_RAW,CUSTO_FRETE_RAW,CIDADE_DESTINO,STATUS_ENTREGA\n",
    "L9001,2024-05-10,15.50,Sao Paulo,ENTREGUE\n",
    "L9002,2024/05/11,22,00,Rio,Em Trânsito\n",
    "L9003,2024-05-12,100.00,Salvador,\n",
    "L9004,2024-05-12,,BH,PENDENTE\n",
    "L9004,2024-05-12,,BH,PENDENTE\n",
    "\"\"\"\n",
    "# A escrita deve ser feita no caminho_completo\n",
    "with open(caminho_completo, \"w\") as f:\n",
    "    f.write(csv_content)\n",
    "print(f\"Arquivo de Logística Bruto gerado em: {caminho_completo}\")\n",
    "\n",
    "# --- PONTO DE PARTIDA DO ALUNO: LEITURA ---\n",
    "\n",
    "# Defina o Schema (TODAS COMO StringType)\n",
    "schema_logistica = StructType([\n",
    "    StructField(\"ID_RASTREIO\", StringType(), nullable=False),\n",
    "    StructField(\"DATA_ENVIO_RAW\", StringType(), nullable=True),\n",
    "    StructField(\"CUSTO_FRETE_RAW\", StringType(), nullable=True),\n",
    "    StructField(\"CIDADE_DESTINO\", StringType(), nullable=True),\n",
    "    StructField(\"STATUS_ENTREGA\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "# Carregar o DataFrame para teste\n",
    "# A leitura deve usar o mesmo caminho_completo\n",
    "df_logistica_raw = (\n",
    "    spark.read\n",
    "    .csv(\n",
    "        caminho_completo,\n",
    "        header=True,\n",
    "        schema=schema_logistica,\n",
    "        sep=\",\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n--- INGESTÃO BEM-SUCEDIDA (5 linhas brutas) ---\")\n",
    "df_logistica_raw.show()\n",
    "df_logistica_raw.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2699b6b6-e5bc-4984-bdf2-25eb971e54e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Schema Original (Raw) ---\n",
      "root\n",
      " |-- ID_RASTREIO: string (nullable = true)\n",
      " |-- DATA_ENVIO_RAW: string (nullable = true)\n",
      " |-- CUSTO_FRETE_RAW: string (nullable = true)\n",
      " |-- CIDADE_DESTINO: string (nullable = true)\n",
      " |-- STATUS_ENTREGA: string (nullable = true)\n",
      "\n",
      "\n",
      "--- Primeiros Registros ---\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "|ID_RASTREIO|DATA_ENVIO_RAW|CUSTO_FRETE_RAW|CIDADE_DESTINO|STATUS_ENTREGA|\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "|L9001      |2024-05-10    |15.50          |Sao Paulo     |ENTREGUE      |\n",
      "|L9002      |2024/05/11    |22             |00            |Rio           |\n",
      "|L9003      |2024-05-12    |100.00         |Salvador      |NULL          |\n",
      "|L9004      |2024-05-12    |NULL           |BH            |PENDENTE      |\n",
      "|L9004      |2024-05-12    |NULL           |BH            |PENDENTE      |\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-requisito: Defina o StructType que trate todas as colunas como StringType.\n",
    "schema_logistico = StructType([\n",
    "    StructField(\"ID_RASTREIO\", StringType(), nullable=False),\n",
    "    StructField(\"DATA_ENVIO_RAW\", StringType(), nullable=True), # O tipo original é String, pois o formato é inconsistente ('2024-03-20' vs '2024/03/20')\n",
    "    StructField(\"CUSTO_FRETE_RAW\", StringType(), nullable=True),  # O tipo original é String, pois pode vir com vírgula (250,99) ou nulo\n",
    "    StructField(\"CIDADE_DESTINO\", StringType(), nullable=True),\n",
    "    StructField(\"STATUS_ENTREGA\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "df_logistico_raw = (\n",
    "    spark.read\n",
    "    .csv(\n",
    "        caminho_completo,\n",
    "        header=True,\n",
    "        schema=schema_logistico,\n",
    "        sep=\",\",\n",
    "        # O PySpark lê a primeira linha como cabeçalho\n",
    "        # e garante que os dados sigam o schema definido (Data Quality!)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n--- Schema Original (Raw) ---\")\n",
    "df_logistico_raw.printSchema()\n",
    "\n",
    "print(\"\\n--- Primeiros Registros ---\")\n",
    "df_logistico_raw.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6be953-114e-408f-b871-993f48ebf2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Limpeza (Cleaning): Nulos Tratados ---\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "|ID_RASTREIO|DATA_ENVIO_RAW|CUSTO_FRETE_RAW|CIDADE_DESTINO|STATUS_ENTREGA|\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "|L9001      |2024-05-10    |15.50          |Sao Paulo     |ENTREGUE      |\n",
      "|L9002      |2024/05/11    |22             |00            |Rio           |\n",
      "|L9003      |2024-05-12    |100.00         |Salvador      |DESCONHECIDO  |\n",
      "|L9004      |2024-05-12    |0.0            |BH            |PENDENTE      |\n",
      "|L9004      |2024-05-12    |0.0            |BH            |PENDENTE      |\n",
      "+-----------+--------------+---------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trate nulos na coluna STATUS_ENTREGA: Se for nulo, preencha com a string \"DESCONHECIDO\".\n",
    "df_limpeza = df_logistico_raw.withColumn(\n",
    "    \"STATUS_ENTREGA\",\n",
    "    F.coalesce(F.col(\"STATUS_ENTREGA\"), F.lit(\"DESCONHECIDO\")) # Coalesce pega o primeiro valor não nulo\n",
    ")\n",
    "\n",
    "# Trate nulos na coluna CUSTO_FRETE_RAW: Se for nulo, preencha com a string \"0.00\"\n",
    "df_limpeza = df_limpeza.na.fill(value=\"0.0\", subset=['CUSTO_FRETE_RAW'])\n",
    "\n",
    "print(\"\\n--- 1. Limpeza (Cleaning): Nulos Tratados ---\")\n",
    "df_limpeza.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ffa2fd-dcd8-4755-bca7-b6028de2376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Transformação: Padronização e Casting ---\n",
      "root\n",
      " |-- ID_RASTREIO: string (nullable = true)\n",
      " |-- CIDADE_DESTINO: string (nullable = true)\n",
      " |-- STATUS_ENTREGA: string (nullable = false)\n",
      " |-- CUSTO_FRETE: double (nullable = true)\n",
      " |-- DATA_ENVIO: date (nullable = true)\n",
      "\n",
      "+-----------+--------------+--------------+-----------+----------+\n",
      "|ID_RASTREIO|CIDADE_DESTINO|STATUS_ENTREGA|CUSTO_FRETE|DATA_ENVIO|\n",
      "+-----------+--------------+--------------+-----------+----------+\n",
      "|L9001      |Sao Paulo     |ENTREGUE      |15.5       |2024-05-10|\n",
      "|L9002      |00            |RIO           |22.0       |2024-05-11|\n",
      "|L9003      |Salvador      |DESCONHECIDO  |100.0      |2024-05-12|\n",
      "|L9004      |BH            |PENDENTE      |0.0        |2024-05-12|\n",
      "|L9004      |BH            |PENDENTE      |0.0        |2024-05-12|\n",
      "+-----------+--------------+--------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, DateType\n",
    "\n",
    "# Crie uma coluna DATA_ENVIO convertendo DATA_ENVIO_RAW para o tipo Date.\n",
    "# Crie uma coluna CUSTO_FRETE convertendo CUSTO_FRETE_RAW para o tipo Double (remova vírgulas antes do cast).\n",
    "# Converta a coluna STATUS_ENTREGA para CAIXA ALTA.\n",
    "df_transformacao = (\n",
    "    df_limpeza\n",
    "    .withColumn(\"STATUS_ENTREGA\", F.upper(F.col(\"STATUS_ENTREGA\")))\n",
    "    .withColumn(\n",
    "        \"CUSTO_FRETE\",\n",
    "        F.regexp_replace(F.col(\"CUSTO_FRETE_RAW\"), \",\", \".\").cast(DoubleType())\n",
    "    )\n",
    "\n",
    "    .withColumn(\n",
    "        \"DATA_ENVIO\",\n",
    "        F.to_date(F.col(\"DATA_ENVIO_RAW\"), \"yyyy-MM-dd\") # Tenta formato padrão, o PySpark pode inferir variações simples\n",
    "    )\n",
    "    .withColumn(\"DATA_ENVIO\", F.coalesce(F.col(\"DATA_ENVIO\"), F.to_date(F.col(\"DATA_ENVIO_RAW\"), \"yyyy/MM/dd\"))) # Tenta o formato com barra, caso o anterior falhe\n",
    "    .drop(\"DATA_ENVIO_RAW\", \"CUSTO_FRETE_RAW\") # Remove as colunas RAW\n",
    ")\n",
    "\n",
    "print(\"\\n--- 2. Transformação: Padronização e Casting ---\")\n",
    "df_transformacao.printSchema()\n",
    "df_transformacao.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039630ba-68aa-4461-984f-59ed1bc05983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Enriquecimento: Nova Feature Adicionada ---\n",
      "+-----------+--------------+--------------+-----------+----------+---------+\n",
      "|ID_RASTREIO|CIDADE_DESTINO|STATUS_ENTREGA|CUSTO_FRETE|DATA_ENVIO|FLAG_CARO|\n",
      "+-----------+--------------+--------------+-----------+----------+---------+\n",
      "|L9001      |Sao Paulo     |ENTREGUE      |15.5       |2024-05-10|false    |\n",
      "|L9002      |00            |RIO           |22.0       |2024-05-11|false    |\n",
      "|L9003      |Salvador      |DESCONHECIDO  |100.0      |2024-05-12|true     |\n",
      "|L9004      |BH            |PENDENTE      |0.0        |2024-05-12|false    |\n",
      "|L9004      |BH            |PENDENTE      |0.0        |2024-05-12|false    |\n",
      "+-----------+--------------+--------------+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crie uma coluna FLAG_CARO: Atribua True se CUSTO_FRETE for maior ou igual a 50.00, senão False.\n",
    "# Ação: Criar uma nova coluna indicando se a venda é considerada de \"Alto Valor\" (> 200)\n",
    "df_enriquecimento = df_transformacao.withColumn(\n",
    "    \"FLAG_CARO\",\n",
    "    F.when(F.col(\"CUSTO_FRETE\") >= 50, F.lit(True)).otherwise(F.lit(False))\n",
    ")\n",
    "\n",
    "print(\"\\n--- 3. Enriquecimento: Nova Feature Adicionada ---\")\n",
    "df_enriquecimento.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5224290-5fd0-4345-b9b2-d7b04a4cba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. Desduplicação: Registros Únicos (5 vs 4) ---\n",
      "+-----------+--------------+--------------+-----------+----------+---------+\n",
      "|ID_RASTREIO|CIDADE_DESTINO|STATUS_ENTREGA|CUSTO_FRETE|DATA_ENVIO|FLAG_CARO|\n",
      "+-----------+--------------+--------------+-----------+----------+---------+\n",
      "|L9001      |Sao Paulo     |ENTREGUE      |15.5       |2024-05-10|false    |\n",
      "|L9002      |00            |RIO           |22.0       |2024-05-11|false    |\n",
      "|L9003      |Salvador      |DESCONHECIDO  |100.0      |2024-05-12|true     |\n",
      "|L9004      |BH            |PENDENTE      |0.0        |2024-05-12|false    |\n",
      "+-----------+--------------+--------------+-----------+----------+---------+\n",
      "\n",
      "root\n",
      " |-- ID_RASTREIO: string (nullable = true)\n",
      " |-- CIDADE_DESTINO: string (nullable = true)\n",
      " |-- STATUS_ENTREGA: string (nullable = false)\n",
      " |-- CUSTO_FRETE: double (nullable = true)\n",
      " |-- DATA_ENVIO: date (nullable = true)\n",
      " |-- FLAG_CARO: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use ID_RASTREIO como chave e remova as duplicatas. O resultado final deve ter 4 linhas.\n",
    "colunas_chave = [\"ID_RASTREIO\"]\n",
    "\n",
    "# Ação: Remover duplicatas estritas\n",
    "df_curated = df_enriquecimento.dropDuplicates(subset=colunas_chave)\n",
    "\n",
    "print(f\"\\n--- 5. Desduplicação: Registros Únicos ({df_enriquecimento.count()} vs {df_curated.count()}) ---\")\n",
    "df_curated.show(truncate=False)\n",
    "df_curated.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6aa9116-ad0f-4901-8587-a7632a33a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Escrita em Parquet concluída ---\n",
      "Dados salvos e particionados em: data/curated/logistica_parquet\n"
     ]
    }
   ],
   "source": [
    "# Salve o DataFrame em: ./data/curated/logistica_parquet.\n",
    "# Use o modo overwrite.\n",
    "# Particione o dataset fisicamente pela coluna CIDADE_DESTINO.\n",
    "# Definindo o caminho de saída (simulação de um Data Lake)\n",
    "caminho_parquet = \"data/curated/logistica_parquet\"\n",
    "\n",
    "# Ação: Salvar o DataFrame tratado (df_curated) em Parquet\n",
    "(\n",
    "    df_curated.write\n",
    "    .mode(\"overwrite\") # Sobrescreve se o diretório já existir\n",
    "    .partitionBy(\"CIDADE_DESTINO\") # Particionamento físico: otimiza queries que filtram por status\n",
    "    .option(\"compression\", \"snappy\") # Snappy é o padrão (bom trade-off)\n",
    "    .parquet(caminho_parquet)\n",
    ")\n",
    "\n",
    "print(f\"\\n--- 1. Escrita em Parquet concluída ---\")\n",
    "print(f\"Dados salvos e particionados em: {caminho_parquet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da648bbc-d82a-4530-976e-18d4c9936136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.1. Predicate Pushdown: Filtro no Disco ---\n",
      "Total de Registros lidos: 1\n",
      "+-----------+--------------+-----------+----------+---------+--------------+\n",
      "|ID_RASTREIO|STATUS_ENTREGA|CUSTO_FRETE|DATA_ENVIO|FLAG_CARO|CIDADE_DESTINO|\n",
      "+-----------+--------------+-----------+----------+---------+--------------+\n",
      "|      L9003|  DESCONHECIDO|      100.0|2024-05-12|     true|      Salvador|\n",
      "+-----------+--------------+-----------+----------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crie uma variável df_salvador. Leia o arquivo Parquet filtrando apenas as entregas com CIDADE_DESTINO igual a \"Salvador\".\n",
    "df_salvador = spark.read.parquet(caminho_parquet).filter(F.col(\"CIDADE_DESTINO\") == \"Salvador\")\n",
    "\n",
    "print(\"\\n--- 3.1. Predicate Pushdown: Filtro no Disco ---\")\n",
    "print(f\"Total de Registros lidos: {df_salvador.count()}\")\n",
    "df_salvador.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8639e96f-611a-45da-9946-20b91fade9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.2. SerDe: Deserialização Seletiva (Projeção) ---\n",
      "Colunas carregadas: ['ID_RASTREIO', 'FLAG_CARO']\n",
      "root\n",
      " |-- ID_RASTREIO: string (nullable = true)\n",
      " |-- FLAG_CARO: boolean (nullable = true)\n",
      "\n",
      "+-----------+---------+\n",
      "|ID_RASTREIO|FLAG_CARO|\n",
      "+-----------+---------+\n",
      "|      L9003|     true|\n",
      "|      L9001|    false|\n",
      "|      L9004|    false|\n",
      "|      L9002|    false|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crie uma variável df_leve. Leia o arquivo Parquet selecionando (projetando) apenas as colunas ID_RASTREIO e FLAG_CARO.\n",
    "df_projecao = spark.read.parquet(caminho_parquet).select(\"ID_RASTREIO\", \"FLAG_CARO\")\n",
    "\n",
    "print(\"\\n--- 3.2. SerDe: Deserialização Seletiva (Projeção) ---\")\n",
    "print(f\"Colunas carregadas: {df_projecao.columns}\")\n",
    "df_projecao.printSchema()\n",
    "df_projecao.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99071af-888f-4999-8f26-a9dcb2f3afb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
